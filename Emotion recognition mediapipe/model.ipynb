{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angry = pd.read_csv('df_angry.csv')\n",
    "df_disgusted = pd.read_csv('df_disgusted.csv')\n",
    "df_happy = pd.read_csv('df_happy.csv')\n",
    "df_neutral = pd.read_csv('df_neutral.csv')\n",
    "df_sad = pd.read_csv('df_sad.csv')\n",
    "df_shocked = pd.read_csv('df_shocked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       angry\n",
       "1       angry\n",
       "2       angry\n",
       "3       angry\n",
       "4       angry\n",
       "       ...   \n",
       "55    shocked\n",
       "56    shocked\n",
       "57    shocked\n",
       "58    shocked\n",
       "59    shocked\n",
       "Name: emotion, Length: 436, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df_angry, df_disgusted, df_happy, df_neutral, df_sad, df_shocked], axis=0)\n",
    "data[\"emotion\"] = [\"angry\"]*len(df_angry) + [\"disgusted\"]*len(df_disgusted) + [\"happy\"]*len(df_happy) + [\"neutral\"]*len(df_neutral) + [\"sad\"]*len(df_sad) + [\"shocked\"]*len(df_shocked)\n",
    "data[\"emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:  348\n",
      "Test data size:  88\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data size: \", len(train_data))\n",
    "print(\"Test data size: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel function: linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.54      0.27      0.36        26\n",
      "   disgusted       0.38      0.27      0.32        11\n",
      "       happy       0.82      0.75      0.78        12\n",
      "     neutral       0.35      0.76      0.48        17\n",
      "         sad       0.00      0.00      0.00         7\n",
      "     shocked       0.75      0.60      0.67        15\n",
      "\n",
      "    accuracy                           0.47        88\n",
      "   macro avg       0.47      0.44      0.43        88\n",
      "weighted avg       0.51      0.47      0.46        88\n",
      "\n",
      "Kernel function: poly\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       1.00      0.23      0.38        26\n",
      "   disgusted       0.00      0.00      0.00        11\n",
      "       happy       0.31      0.83      0.45        12\n",
      "     neutral       0.30      0.82      0.44        17\n",
      "         sad       0.00      0.00      0.00         7\n",
      "     shocked       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.34        88\n",
      "   macro avg       0.27      0.31      0.21        88\n",
      "weighted avg       0.40      0.34      0.26        88\n",
      "\n",
      "Kernel function: rbf\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       1.00      0.12      0.21        26\n",
      "   disgusted       0.00      0.00      0.00        11\n",
      "       happy       0.39      0.58      0.47        12\n",
      "     neutral       0.21      0.82      0.34        17\n",
      "         sad       0.00      0.00      0.00         7\n",
      "     shocked       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.27        88\n",
      "   macro avg       0.27      0.25      0.17        88\n",
      "weighted avg       0.39      0.27      0.19        88\n",
      "\n",
      "Kernel function: sigmoid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.00      0.00      0.00        26\n",
      "   disgusted       0.00      0.00      0.00        11\n",
      "       happy       0.40      0.17      0.24        12\n",
      "     neutral       0.20      1.00      0.34        17\n",
      "         sad       0.00      0.00      0.00         7\n",
      "     shocked       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.22        88\n",
      "   macro avg       0.10      0.19      0.10        88\n",
      "weighted avg       0.09      0.22      0.10        88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\felip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\felip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\felip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\felip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\felip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\felip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\felip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\felip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\felip\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf_linear = svm.SVC(kernel=\"linear\", C=1)\n",
    "clf_poly = svm.SVC(kernel=\"poly\", C=1)\n",
    "clf_rbf = svm.SVC(kernel=\"rbf\", C=1)\n",
    "clf_sigmoid = svm.SVC(kernel=\"sigmoid\", C=1)\n",
    "clf_linear.fit(train_data, train_labels)\n",
    "clf_poly.fit(train_data, train_labels)\n",
    "clf_rbf.fit(train_data, train_labels)\n",
    "clf_sigmoid.fit(train_data, train_labels)\n",
    "print(\"Kernel function: linear\")\n",
    "print(classification_report(test_labels, clf_linear.predict(test_data)))\n",
    "print(\"Kernel function: poly\")\n",
    "print(classification_report(test_labels, clf_poly.predict(test_data)))\n",
    "print(\"Kernel function: rbf\")\n",
    "print(classification_report(test_labels, clf_rbf.predict(test_data)))\n",
    "print(\"Kernel function: sigmoid\")\n",
    "print(classification_report(test_labels, clf_sigmoid.predict(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf_linear, open('emotion_model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
